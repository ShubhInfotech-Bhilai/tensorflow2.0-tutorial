{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda \n",
    "\n",
    "1. Exploring sample data for schema extraction\n",
    "2. Large data processing using TensorFlow Data Pipeline\n",
    "3. Understanding feature_columns for Data Transformation\n",
    "4. Build Model\n",
    "5. Model Training\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data schema & column names\n",
    "* Pandas can be used here to do this\n",
    "* We need to prepare the schema before loading large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/heart.csv',nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'sex',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal',\n",
       " 'target']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal         object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Data Pipeline for multiple & large data sources\n",
    "* Schema information obtained needs to be used for decoding csv\n",
    "* interleave - process multiple input files\n",
    "* shuffle - randomly shuffles datset, \n",
    "* batch - set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_defaults = [tf.constant([], dtype=tf.int64)] * 9 + \\\n",
    "[tf.constant([], dtype=tf.float64)] + \\\n",
    "[tf.constant([], dtype=tf.int64)] * 2 + \\\n",
    "[tf.constant([], dtype=tf.string)] + \\\n",
    "[tf.constant([], dtype=tf.int64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(line,record_defaults=record_defaults,columns=columns):\n",
    "    fields = tf.io.decode_csv(line, record_defaults=record_defaults)\n",
    "    features = dict(zip(columns,fields))\n",
    "    label = features.pop('target')\n",
    "    return features,label\n",
    "\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from multiple files & create batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = {'age': <tf.Tensor: id=146, shape=(3,), dtype=int64, numpy=array([61, 57, 61])>, 'sex': <tf.Tensor: id=154, shape=(3,), dtype=int64, numpy=array([1, 0, 1])>, 'cp': <tf.Tensor: id=149, shape=(3,), dtype=int64, numpy=array([3, 2, 4])>, 'trestbps': <tf.Tensor: id=158, shape=(3,), dtype=int64, numpy=array([150, 130, 120])>, 'chol': <tf.Tensor: id=148, shape=(3,), dtype=int64, numpy=array([243, 236, 260])>, 'fbs': <tf.Tensor: id=151, shape=(3,), dtype=int64, numpy=array([1, 0, 0])>, 'restecg': <tf.Tensor: id=153, shape=(3,), dtype=int64, numpy=array([0, 2, 0])>, 'thalach': <tf.Tensor: id=157, shape=(3,), dtype=int64, numpy=array([137, 174, 140])>, 'exang': <tf.Tensor: id=150, shape=(3,), dtype=int64, numpy=array([1, 0, 1])>, 'oldpeak': <tf.Tensor: id=152, shape=(3,), dtype=float64, numpy=array([1. , 0. , 3.6])>, 'slope': <tf.Tensor: id=155, shape=(3,), dtype=int64, numpy=array([2, 2, 2])>, 'ca': <tf.Tensor: id=147, shape=(3,), dtype=int64, numpy=array([0, 1, 1])>, 'thal': <tf.Tensor: id=156, shape=(3,), dtype=string, numpy=array([b'normal', b'normal', b'reversible'], dtype=object)>}\n",
      "y = tf.Tensor([0 0 1], shape=(3,), dtype=int64)\n",
      "X = {'age': <tf.Tensor: id=174, shape=(3,), dtype=int64, numpy=array([47, 52, 39])>, 'sex': <tf.Tensor: id=182, shape=(3,), dtype=int64, numpy=array([1, 1, 0])>, 'cp': <tf.Tensor: id=177, shape=(3,), dtype=int64, numpy=array([3, 4, 3])>, 'trestbps': <tf.Tensor: id=186, shape=(3,), dtype=int64, numpy=array([138, 125, 138])>, 'chol': <tf.Tensor: id=176, shape=(3,), dtype=int64, numpy=array([257, 212, 220])>, 'fbs': <tf.Tensor: id=179, shape=(3,), dtype=int64, numpy=array([0, 0, 0])>, 'restecg': <tf.Tensor: id=181, shape=(3,), dtype=int64, numpy=array([2, 0, 0])>, 'thalach': <tf.Tensor: id=185, shape=(3,), dtype=int64, numpy=array([156, 168, 152])>, 'exang': <tf.Tensor: id=178, shape=(3,), dtype=int64, numpy=array([0, 0, 0])>, 'oldpeak': <tf.Tensor: id=180, shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>, 'slope': <tf.Tensor: id=183, shape=(3,), dtype=int64, numpy=array([1, 1, 2])>, 'ca': <tf.Tensor: id=175, shape=(3,), dtype=int64, numpy=array([0, 2, 0])>, 'thal': <tf.Tensor: id=184, shape=(3,), dtype=string, numpy=array([b'normal', b'reversible', b'normal'], dtype=object)>}\n",
      "y = tf.Tensor([0 1 0], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_set = csv_reader_dataset(['data/heart.csv'], batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns\n",
    "* Feature columns as the intermediaries between raw data and Estimators. \n",
    "* Feature columns are very rich, enabling you to transform a diverse range of raw data into formats that Estimators can use, allowing easy experimentation.\n",
    "* What kind of data can a deep neural network operate on? The answer is, of course, numbers (for example, tf.float32). \n",
    "* Some examples are - numeric_column, bucketized_column, categorical_column_with_vocabulary_list etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit-testing transformation\n",
    "example_batch = next(iter(train_set))[0]\n",
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.]\n",
      " [57.]\n",
      " [61.]]\n"
     ]
    }
   ],
   "source": [
    "age = feature_column.numeric_column(\"age\")\n",
    "demo(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "demo(age_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 15:43:53.053673 140600608700224 deprecation.py:323] From /home/awantik/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0727 15:43:53.346688 140600608700224 deprecation.py:323] From /home/awantik/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0727 15:43:53.348438 140600608700224 deprecation.py:323] From /home/awantik/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'thal', ['fixed', 'normal', 'reversible'])\n",
    "\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "demo(thal_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.28974992  0.2767802  -0.289907    0.16144833  0.4364657   0.3567376\n",
      "  -0.0526059   0.05884144]\n",
      " [-0.28974992  0.2767802  -0.289907    0.16144833  0.4364657   0.3567376\n",
      "  -0.0526059   0.05884144]\n",
      " [-0.06115608 -0.22891812  0.08867108 -0.4072269  -0.25880584  0.10197378\n",
      "  -0.16998404  0.0012828 ]]\n"
     ]
    }
   ],
   "source": [
    "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "demo(thal_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# bucketized cols\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# indicator cols\n",
    "thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'thal', ['fixed', 'normal', 'reversible'])\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "feature_columns.append(thal_one_hot)\n",
    "\n",
    "# embedding cols\n",
    "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "feature_columns.append(thal_embedding)\n",
    "\n",
    "# crossed cols\n",
    "crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
    "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
    "feature_columns.append(crossed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='trestbps', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='chol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='thalach', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='oldpeak', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='slope', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='ca', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible'), dtype=tf.string, default_value=-1, num_oov_buckets=0), dimension=8, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fdfd42237f0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " IndicatorColumn(categorical_column=CrossedColumn(keys=(BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), VocabularyListCategoricalColumn(key='thal', vocabulary_list=('fixed', 'normal', 'reversible'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=1000, hash_key=None))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "* 1st layer for feature preprocessing\n",
    "* Rest of the layers are neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 15:46:20.501655 140600608700224 deprecation.py:323] From /home/awantik/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 4s 39ms/step - loss: 0.8640 - accuracy: 0.6368 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.6039 - accuracy: 0.6983 - val_loss: 0.8125 - val_accuracy: 0.7261\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5413 - accuracy: 0.7923 - val_loss: 0.8014 - val_accuracy: 0.7261\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5280 - accuracy: 0.7954 - val_loss: 0.8514 - val_accuracy: 0.7261\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 3s 26ms/step - loss: 0.5123 - accuracy: 0.7903 - val_loss: 0.7728 - val_accuracy: 0.7261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdfd44a1da0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)\n",
    "\n",
    "model.fit(train_set,\n",
    "          validation_data=train_set,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
